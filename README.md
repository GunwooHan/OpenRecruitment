# ì´ëŸ° ë¶„ì„ ì°¾ìŠµë‹ˆë‹¤!

---
## íŒ€ì›ì—ê²Œ ë°”ë¼ëŠ” ì 
- ìë£Œ ì •ë¦¬ë¥¼ ì˜í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”! 
- ì°¸ì—¬ê°€ ì ê·¹ì ì´ê³  ì˜ì‚¬ì†Œí†µì´ í™œë°œí–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”!
- ì„œë¡œë¥¼ ì¡´ì¤‘í•˜ê³  ì˜ˆì˜ë¥¼ ê°–ì¶°ì¤¬ìœ¼ë©´ ì¢‹ê² ì–´ìš”!
- ì§€ì¹˜ë”ë¼ë„ ëê¹Œì§€ í¬ê¸°í•˜ì§€ ì•Šê³  ë§ˆë¬´ë¦¬í•  ìˆ˜ ìˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤!
- ëª¨ë¥´ëŠ” ì ì— ëŒ€í•´ ë¶€ë„ëŸ¬ì›Œí•˜ì§€ ì•Šê³  ì§ˆë¬¸í•´ì£¼ë©´ ì¢‹ê² ì–´ìš”! ì§ˆë¬¸ì´ ë§ì•„ë„ ê´œì°®ì•„ìš”!
- gitì„ ì˜ ëª°ë¼ë„ ê´œì°®ì•„ìš”! ì €ë„ ì˜ ëª»í•´ì„œ ê°™ì´ ê³µë¶€í•˜ë©´ì„œ í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”!
---
## ìš°ë¦¬ ì¡°ëŠ” ì´ë ‡ê²Œ ì§„í–‰í•˜ê³  ì‹¶ì–´ìš”!

---
### íšŒì˜ëŠ” ì´ë ‡ê²Œ í• ê±°ì—ìš”!
- ëª¨ë“  íŒ€ì›ì´ ê°ì ê³µë¶€í•œ ë‚´ìš©ì´ë‚˜ ìƒˆë¡œ ì•Œê²Œëœ ê²ƒ, ë³„ë„ë¡œ ì •ë¦¬í•œ ë‚´ìš©ë“±ì„ ììœ ë¡­ê²Œ ê³µìœ í•©ë‹ˆë‹¤!
- ëª¨ë“  íšŒì˜ëŠ” ìˆ˜ì—… ë‚´ìš©, ëŒ€íšŒ ìƒí™©ì— ë”°ë¼ ìœ ë™ì ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤!
- íŒ€ì›ìœ¼ë¡œ í•©ë¥˜í•˜ì‹œë©´ ì•ìœ¼ë¡œ ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í• ì§€ì— ëŒ€í•´ì„œë„ ê°™ì´ ì´ì•¼ê¸°í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”!


### ì½”ë“œ ì‘ì„±ì€ ì´ë ‡ê²Œ í• ê±°ì—ìš”!
- ì„œë¡œ ì½”ë“œë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ **Pytorch lightning**ë¡œ êµ¬í˜„í• ê±°ì—ìš”!
    ```python
    if __name__ == '__main__':
        seed_fix(args.seed)
        train_transform, test_transform = make_transform(args)
        dataset = ImageBaseDataset(data_dir='train/train/images', transform=test_transform)
        train_dataset, valid_dataset = dataset.split_dataset()

        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)
        val_loader = DataLoader(valid_dataset, batch_size=128, num_workers=4)

        # model
        model = CustomModel(model_name=args.model, num_classes=18)

        # training
        trainer = pl.Trainer(max_epochs=args.epochs, gpus=2, accelerator="dp")
        trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)

    ```
- train í•¨ìˆ˜ì— ëˆ„ë•ëˆ„ë• êµ¬í˜„í•˜ì§€ ì•Šê³  **í´ë˜ìŠ¤ ë‹¨ìœ„ë¡œ ê°œë°œ**í•´ì„œ ì‚¬ìš©í• ê±°ì—ìš”!

    ```python
    class FocalLoss(nn.Module):
        def __init__(self, weight=None, gamma=2., reduction='mean'):
            nn.Module.__init__(self)
            self.weight = weight
            self.gamma = gamma
            self.reduction = reduction
        def forward(self, input_tensor, target_tensor):
            log_prob = F.log_softmax(input_tensor, dim=-1)
            prob = torch.exp(log_prob)
            return F.nll_loss(
                ((1 - prob) ** self.gamma) * log_prob,
                target_tensor,
                weight=self.weight,
                reduction=self.reduction)

    -------------------------------------------------------------------------

    class CustomModel(pl.LightningModule):

        def __init__(self, model_name='tf_efficientnet_b0', num_classes=18):
            self.focal_loss = FocalLoss()
        ...

        def training_step(self, train_batch, batch_idx):
            x, y = train_batch
            x = x.view(x.size(0), -1)
            z = self.encoder(x)
            x_hat = self.decoder(z)
            loss = self.focal_loss(x_hat, x)      # Loss ìˆ˜ì •
            wandb.log('val_loss', loss)

    ```
- **argparse**ë¥¼ í™œìš©í•˜ì—¬ **wandb** hyper parameter tuning ì‚¬ìš©í•´ ì‹¤í—˜í•  ê±°ì—ìš”!

    ```python
    parser = argparse.ArgumentParser()

    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--data_dir', type=str, default='data')
    parser.add_argument('--dataset', type=str, default='base')
    parser.add_argument('--save_path', type=str, default='saved')
    parser.add_argument('--num_workers', type=int, default=0)

    parser.add_argument('--label_type', type=str, default='all')

    parser.add_argument('--img_size', type=int, default=256)
    parser.add_argument('--batch_size', type=int, default=128)
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--learning_rate', type=float, default=0)
    parser.add_argument('--optimizer', type=str, default='adam')
    parser.add_argument('--test_size', type=float, default=0.2)

    ...

    args = parser.parse_args()
    ```
    - ì´ì „ Competitionì—ëŠ” ì´ë§Œí¼ ì‹¤í—˜í–ˆì–´ìš”!ğŸ™†â€â™€ï¸
    ![](https://i.imgur.com/YriH5Gi.png)

    
---

## íŒ€ì› ì†Œê°œ
- `ë°•ë²”ìˆ˜` : í•™ë¶€ìƒë•Œ ì„ë² ë””ë“œ, C#ì„ ìœ„ì£¼ë¡œ í•˜ë‹¤ê°€ í”„ë¡œê·¸ë˜ë°ì„ í•˜ë‹¤ê°€ ì´ë²ˆì— ë³¸ê²©ì ìœ¼ë¡œ CVì— ëŒ€í•´ ê´€ì‹¬ì´ ìƒê²¨ í•©ë¥˜í•˜ê²Œ ëìŠµë‹ˆë‹¤! ì•„ì§ ë¶€ì¡±í•œ ë¶€ë¶„ì´ ë§ì•„ ì„œë¡œ í˜‘ë ¥í•˜ë©´ì„œ ë°°ì›Œë‚˜ê°€ê³  ì‹¶ìŠµë‹ˆë‹¤!
- `í•œê±´ìš°` : GANìœ¼ë¡œ ì•„ì´ëŒì„ ë§Œë“¤ë‹¤ ë¶€ìŠ¤íŠ¸ìº í”„ì— í•©ë¥˜í–ˆì–´ìš”! Segmentationë„ ì¡°ê¸ˆ í• ì¤„ ì•Œì•„ìš”! ê°™ì´ ì„±ì¥í•˜ë©´ì„œ ë¶€ìŠ¤íŠ¸ìº í”„ê°€ ëë‚˜ë„ ì­‰ ì•Œê³ ì§€ëƒˆìœ¼ë©´ ì¢‹ê² ì–´ìš”! 
  - ë§Œë“¤ë˜ ì•„ì´ëŒ ì˜ìƒ : https://youtu.be/biIVEH7-Rao
  - ë…¼ë¬¸ì€ ìš”ì •ë„ ì½ì–´ìš”!
      - Pyramid Attention Network for Semantic Sementation : https://docs.google.com/presentation/d/15jgE8P26fH_BdZTJTNH6fm0IIRjTzbXk/edit?usp=sharing&ouid=107012802823432471585&rtpof=true&sd=true
      - CartoonGAN : https://docs.google.com/presentation/d/14x06uOQKxgoqbkYZUbXWn_Myenn9o16v/edit?usp=sharing&ouid=107012802823432471585&rtpof=true&sd=true
      - RetinaFace(2020) : https://docs.google.com/presentation/d/1-AR-jTFyR5w2BIIRXJfD22CdfvDTPA86/edit?usp=sharing&ouid=107012802823432471585&rtpof=true&sd=true
- `ë°•ì¤€í˜` : ë¹„ì „ê³µìë¡œì„œ ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ë¡œ ì‘ë…„ë¶€í„° ì…ë¬¸í–ˆìŠµë‹ˆë‹¤! ë¶„ì„ìª½ìœ¼ë¡œ ê³µë¶€í–ˆì—ˆê³ , ì—”ì§€ë‹ˆì–´ì™€ ë¹„ì „ìª½ì€ ì´ì œ ë°°ì›Œë‚˜ê°€ëŠ” ë‹¨ê³„ë¼ ê°™ì´ ì„±ì¥í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”!! (à¸‡ â€¢Ì€á´—â€¢Ì)à¸‡ 
    - https://docs.google.com/presentation/d/1G1gMfB_oJsaf5C2pGXzWdNB6gF0b_PnEQUhaWguI9Jg/edit#slide=id.geeefed5b4b_0_0
- `ì¡°í˜œì›` : ì €ëŠ” ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ìˆ˜ë£Œìƒì´ê³ , ì¸ê³µì§€ëŠ¥ ë¶€ì„œì—ì„œ ì¸í„´ì„ í•˜ë‹¤ê°€ ì €ì˜ ë†€ë¼ìš´ ê°ìë ¥ì„ ê¹¨ë‹«ê³  ë¶€ìŠ¤íŠ¸ìº í”„ì— í•©ë¥˜í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤!í•¨ê»˜ ìœ¼ìŒ°ìœ¼ìŒ°í•˜ë©´ì„œ ì„±ì¥í•˜ê³  ì‹¶ì–´ìš” Ù©( á› )Ùˆ

---
